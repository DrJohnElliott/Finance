{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bee8851-db60-45de-91ae-1abcec54cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.1 (v3.10.1:2cd268a3a9, Dec  6 2021, 14:28:59) [Clang 13.0.0 (clang-1300.0.29.3)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f59229-e51c-48a4-bcb6-fef7e8df0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83aa1897-adff-4b7f-84bf-81b94869818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_wiki_page = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies' \n",
    "sp500_ticker_csv = \"data/sp500_ticker_sector.csv\"\n",
    "\n",
    "nas100_wiki_page = 'https://en.wikipedia.org/wiki/Nasdaq-100'\n",
    "nas100_ticker_csv = \"data/nasdaq100_ticker_sector.csv\"\n",
    "\n",
    "combined_data_csv = \"data/combined_data.csv\"\n",
    "\n",
    "combined_tickers_csv = \"data/combined_ticker_sector.csv\"\n",
    "\n",
    "update_log_csv = \"data/update_log.csv\"\n",
    "#records_df = pd.read_csv(update_log_csv)\n",
    "\n",
    "#historical_data = records_df.iloc[1,1]\n",
    "updated_data  = \"data/combined_data_\"+ date.today().strftime('%Y-%m-%d') + \".csv\"\n",
    "\n",
    "\n",
    "\n",
    "start_default = datetime.datetime(2015, 1, 1)\n",
    "# end = datetime.datetime(2023, 9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52e482d-e5cd-4ff2-92df-fe383cbc70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_port = ['TBIL', 'TFLO','FXC', 'IAK', 'INDA', 'EWJV','USO', 'NLR',\n",
    "                'AMLP', 'UAE', 'URA', 'SMIN', 'URA', 'EWJ', 'XLE',\n",
    "                'PFIX', 'INDY', 'GLD', 'PSCE', 'AAAU', 'XOP', 'UGA', 'BDRY', 'CTA', 'CYA']\n",
    "\n",
    "stock_port = ['COST','DIS','WMT','NEM', 'MELI','VVV','DKNG', 'ATVI','MNSO','V','PCT',\n",
    "             'MNST','FL','MTCH','CCL','PRGO','NYT','PLBY','TCS','YUMC','REAL','EDU','MSOS']\n",
    "\n",
    "sectors = ['XLY','XLF','XLV','XLC','XLK','XLP','XLI','XLB','XLE','XLRE','XLU','^SPX']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18854d96-9c3f-4224-bb6d-253d67bf4ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea7b55b-3d9e-45a5-8b3f-d3adf9f33306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yahoo_last_day(ticker='GOOGL', period='1wk', interval='1d', \n",
    "                   observation='Close'):\n",
    "    \"\"\"Gets last date of avalible data from yahoo finance.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        ticker : str, not required\n",
    "            default = 'GOOGL'\n",
    "        period : str, not required\n",
    "            default = '1wk'\n",
    "        interval : str, not required\n",
    "            default = '1d'\n",
    "        observation : str, not required\n",
    "            default = 'Close'\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        last_day : string\n",
    "            last date avalible from yahoo\n",
    "        \"\"\"  \n",
    "    ticker = yf.Ticker(ticker)\n",
    "    ticker_history = ticker.history(period, interval)\n",
    "    sf = ticker_history[observation]\n",
    "    df = pd.DataFrame({'Date':sf.index})\n",
    "    dates = df['Date'].tolist() \n",
    "    last_day = dates\n",
    "\n",
    "    return last_day\n",
    "\n",
    "\n",
    "def get_start_end(df):\n",
    "    \"\"\"Determines if new data is available and calculates starting\n",
    "    and ending dates for getting data from yahoo finance. \n",
    "    (if no new data available, returns same values for start and end) \n",
    "                                                                       \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : dataframe, required\n",
    "            dataframe of historical ticker price data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        start : string\n",
    "            date string of starting date\n",
    "        end : string\n",
    "            date string of ending date\n",
    "        \"\"\"  \n",
    "    \n",
    "    last_day = df.index.max() \n",
    "    last_date = yahoo_last_day()\n",
    "    if last_day == last_date[-1].strftime('%Y-%m-%d'):\n",
    "        start = last_day\n",
    "        end = last_day\n",
    "    else: \n",
    "        date_1 = datetime.datetime.strptime(last_day, \"%Y-%m-%d\")\n",
    "        start = date_1 + datetime.timedelta(days=1)\n",
    "        today = date.today().strftime('%Y-%m-%d')\n",
    "        end = datetime.datetime.strptime(today, \"%Y-%m-%d\") \n",
    "        \n",
    "    \n",
    "    return (start, end)\n",
    "\n",
    "def get_ticker_data(wiki_page, table_location):\n",
    "    \"\"\"Gets Wiki page of tickes for SP500 and NAS100.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        table_location : int, required\n",
    "            location of table on wiki page\n",
    "        Returns\n",
    "        -------\n",
    "        table ; dataframe\n",
    "        a data frame of the Ticker information\n",
    "        \"\"\"\n",
    "    table=pd.read_html(wiki_page)\n",
    "    ticker_df = table[table_location]\n",
    "    return ticker_df\n",
    "\n",
    "def get_ticker_list(df, column_name):\n",
    "    \"\"\"Reformats ticker names for yahoo,\n",
    "    returns df and list with corrected names\n",
    "                                                                                        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : dataframe, required\n",
    "            dataframe containing tickers\n",
    "        column_name : string, required\n",
    "            name of the column tickers are located\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        df : dataframe\n",
    "            original datframe with corrected ticker names\n",
    "        tickers : list(str)\n",
    "            list of tickers from dataframe\n",
    "        \"\"\"\n",
    "    \n",
    "    for x, ticker in enumerate(list(df[column_name])):\n",
    "        if ticker.rfind('.'):\n",
    "            df.loc[x,column_name] = ticker.replace(\".\", \"-\")\n",
    "    tickers = list(df[column_name])\n",
    "    return (df, tickers)\n",
    "\n",
    "def save_data(df, filename, index=False):\n",
    "    \"\"\"Saves dataframe at defined path/name.csv. \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : dataframe, required\n",
    "            dataframe to be saved\n",
    "        filename : string, required\n",
    "            path, name and ext(.csv) of the file to be saved\n",
    "        Index : logical, not required \n",
    "            Default - False\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        df : dataframe\n",
    "            original datframe with corrected ticker names\n",
    "        tickers : list(str)\n",
    "            list of tickers from dataframe\n",
    "        \"\"\"\n",
    "    \n",
    "    df.to_csv(filename,index=index)\n",
    "\n",
    "def check_for_data(df_to_read, wiki_page, table, column_name):\n",
    "    \"\"\"Checks if file exists, if not gets ticker data and saves file\n",
    "        Used only for retriving SP500 and NAS100 data from wiki.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        df_to_read : string, required\n",
    "            read/save location (path/name.csv)\n",
    "        wiki_page : string, required\n",
    "            wiki page html\n",
    "        table : int, required\n",
    "            location of table on wiki page\n",
    "        column_name : string, required\n",
    "            name of the column tickers are located in the table\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ticker_df\n",
    "            original datframe with corrected ticker names\n",
    "        ticker_list\n",
    "            list of tickers from dataframe\n",
    "        \"\"\"\n",
    "    \n",
    "    path = Path(df_to_read)\n",
    "    if (True!= path.is_file()):\n",
    "        ticker_df = get_ticker_data(wiki_page, table)\n",
    "        ticker_df, ticker_list = get_ticker_list(ticker_df,column_name )\n",
    "        save_data(ticker_df, df_to_read)\n",
    "        \n",
    "    else:\n",
    "        ticker_df = pd.read_csv(df_to_read)\n",
    "        ticker_df, ticker_list = get_ticker_list(ticker_df,column_name )\n",
    "        \n",
    "    return ticker_df, ticker_list  \n",
    "    \n",
    "def update_stock_data(tickers, hist_df, start, end, file_name):\n",
    "    \"\"\"Gets data from yahoo finance if it is available\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        tickers : list(str), required\n",
    "            list of tickers to get yahoo data\n",
    "        hist_df : dataframe, required\n",
    "            stored data to be updated\n",
    "        start : str, required\n",
    "            start date\n",
    "        end : string, required\n",
    "            end date\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        hist_df : dataframe\n",
    "            dataframe of ticker data (updated if data is available)\n",
    "        \n",
    "        \"\"\"\n",
    "    if end > start:\n",
    "        print('Get Data')\n",
    "        stock_prices = yf.download(tickers, start=start, end=end)\n",
    "        stock_prices.index = stock_prices.index.strftime('%Y-%m-%d')\n",
    "        current_stock_prices = pd.concat([hist_df, stock_prices])\n",
    "        current_stock_prices.to_csv(file_name)\n",
    "        return current_stock_prices\n",
    "    else:\n",
    "        \n",
    "        print(f\"Stock Prices are up to date {end}\")\n",
    "        return  hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998b1af8-8cec-42f1-90ce-7d98a521972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get main Ticker data\n",
    "sp500_ticker_df, sp500_ticker_list  = check_for_data(sp500_ticker_csv,\n",
    "                                            sp500_wiki_page, 0, 'Symbol')\n",
    "nas100_ticker_df, nas100_ticker_list = check_for_data(nas100_ticker_csv,\n",
    "                                            nas100_wiki_page, 4, 'Ticker')                                                                                                                                                    \n",
    "# Create combined ticker list of SP500 and NAS100\n",
    "SP500_NAS100_tkrs = sp500_ticker_list + \\\n",
    "                   list(set(nas100_ticker_list).difference(sp500_ticker_list)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82963954-8cf7-4ef5-9e63-89032a6a8b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_tickers(SP500_NAS100=SP500_NAS100_tkrs, my_stocks=stock_port,\n",
    "                         my_etfs=etf_port, secttor_port=sectors):                       \n",
    "    \"\"\"compiles list of tickers from all ticker list sources\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        SP500_NAS100 : list(str), not required\n",
    "            SP500 and NAS100 tickers unique values\n",
    "            default = SP500_NAS100_tkrs : list(str)\n",
    "        my_stocks : list(str), not required\n",
    "            Portfolio stock tickers \n",
    "            default = stock_port : list(str)\n",
    "        my_etfs : list(str), not required\n",
    "            Portfolio etf tickers \n",
    "            default = etf_port : list(str)    \n",
    "        sector_port : list(str), not required\n",
    "            Portfolio of sector etf tickers \n",
    "            default = sectors : list(str)     \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        all_tickers : list(str)\n",
    "            list of unique tickers from all lists\n",
    "        missing_tickers : list(str)\n",
    "            list of missing tickers from historical lists\n",
    "        \"\"\"                     \n",
    "    \n",
    "    missing_stocks = list(set(my_stocks).difference(SP500_NAS100)) \n",
    "    missing_portfolio  = list(set(my_etfs).difference(SP500_NAS100))  \n",
    "    missing_sectors  = list(set(sectors).difference(SP500_NAS100))  \n",
    "    missing_tickers = missing_stocks + missing_portfolio + missing_sectors\n",
    "    all_tickers = list(set(SP500_NAS100 + missing_tickers))\n",
    "    \n",
    "    return all_tickers, missing_tickers   \n",
    "\n",
    "\n",
    "def update_tickers(combined_tickers_csv, combined_tickers=SP500_NAS100_tkrs,\n",
    "                   column_name='Symbol'):\n",
    "    \"\"\"Checks if file exists, if not gets ticker data and saves file\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        combined_tickers_csv : string, required\n",
    "            read/save location (path/name.csv)\n",
    "        combined_tickers : list(str), not required\n",
    "            list of SP500 and NAS100 unique tickers \n",
    "            Default = SP500_NAS100\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        all_ticker_df\n",
    "            original datframe with corrected ticker names\n",
    "        all_tickers\n",
    "            list of tickers from dataframe\n",
    "        missing_tickers\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "    path = Path(combined_tickers_csv)  # check if file exists\n",
    "    if (True!= path.is_file()):        # create file if not\n",
    "        all_tickers, missing_tickers = get_combined_tickers( )\n",
    "        all_ticker_df = pd.DataFrame(all_tickers, columns = [column_name])\n",
    "        save_data(all_ticker_df, combined_tickers_csv)\n",
    "            \n",
    "    else: # else get historical tickers from file\n",
    "        all_ticker_df = pd.read_csv(combined_tickers_csv)\n",
    "        all_ticker_df, all_ticker_lst = get_ticker_list(all_ticker_df, column_name)                                                                  \n",
    "        all_tickers, missing_tickers = get_combined_tickers(all_ticker_lst)\n",
    "        \n",
    "        if missing_tickers !=[]:\n",
    "            new_list =  missing_tickers + all_tickers\n",
    "            new_list_df = pd.DataFrame(new_list, columns = [column_name])\n",
    "            save_data(new_list_df, combined_tickers_csv)                                                                              \n",
    "    return all_ticker_df, all_tickers, missing_tickers\n",
    "                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10e506-5585-4b47-bf6a-6825019c978a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ed1eb-8e44-4326-9f2a-b8bd287e00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcbc18c-d868-46d0-8349-a4d939ef4ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4825c4a9-23c1-4978-a035-b20fcf4feb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_ticker_df, ticker_list, new_tickers = update_tickers(combined_tickers_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a568e82-919b-413d-b066-70edb7c9717d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"s = ['CTA']\\np=ticker_list\\ns in new_tickers\\n\\nprint(list(set(s).difference(p)) )\\nprint(s)\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''s = ['CTA']\n",
    "p=ticker_list\n",
    "s in new_tickers\n",
    "\n",
    "print(list(set(s).difference(p)) )\n",
    "print(s)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161d4b7-7dfa-418d-bc97-d529921f9470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a761f51-25c9-411d-8f69-b7038e25276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Data\n",
      "[*********************100%%**********************]  569 of 569 completed\n"
     ]
    }
   ],
   "source": [
    "path = Path(update_log_csv)\n",
    "all_ticker_df, ticker_list, new_tickers = update_tickers(combined_tickers_csv)\n",
    "if (True!= path.is_file()):\n",
    "    \n",
    "    end = datetime.datetime.strptime(date.today().strftime('%Y-%m-%d'), \"%Y-%m-%d\") \n",
    "    hist_stock_prices = pd.DataFrame()\n",
    "    latest_prices = update_stock_data(ticker_list, hist_stock_prices,\n",
    "                                      start_default, end, updated_data)\n",
    "   \n",
    "    last_record = end\n",
    "    log={\n",
    "        'last_update' : last_record,\n",
    "        'file_name' : updated_data,\n",
    "    }\n",
    "    df = pd.DataFrame(list(log.items()))\n",
    "    df.to_csv(update_log_csv, index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "else:\n",
    "    records_df = pd.read_csv(update_log_csv)\n",
    "    historical_data = records_df.iloc[1,1]\n",
    "    today = datetime.datetime.today()\n",
    "    hist_stock_prices = pd.read_csv(historical_data, header=[0, 1], low_memory=False, index_col=0)\n",
    "    start, end = get_start_end(hist_stock_prices)\n",
    "    \n",
    "    if end.strftime('%Y-%m-%d') == today.strftime('%Y-%m-%d'):\n",
    "        #if (today.strftime('%H') > str(20)):\n",
    "        latest_prices = update_stock_data(ticker_list, hist_stock_prices, start, end, updated_data)      \n",
    "        ##############\n",
    "        update_log_csv = \"data/update_log.csv\"\n",
    "        last_record = latest_prices.index[-1]\n",
    "        log={\n",
    "            'last_update' : last_record,\n",
    "            'file_name' : updated_data,\n",
    "        }\n",
    "        df = pd.DataFrame(list(log.items()))\n",
    "        df.to_csv(update_log_csv, index=False)\n",
    "        \n",
    "        #else:\n",
    "            #print('Historical data availible after 9:00pm')\n",
    "        \n",
    "    else:\n",
    "        latest_prices = update_stock_data(ticker_list, hist_stock_prices, start, end, updated_data)      \n",
    "        ##############\n",
    "        update_log_csv = \"data/update_log.csv\"\n",
    "        last_record = latest_prices.index[-1]\n",
    "        log={\n",
    "            'last_update' : last_record,\n",
    "            'file_name' : updated_data,\n",
    "        }\n",
    "        df = pd.DataFrame(list(log.items()))\n",
    "        df.to_csv(update_log_csv, index=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390c257-07db-4321-864b-b1c338d67bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438be72-96d7-4aa5-a4d5-9e4040b44ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.today().strftime('%H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160065bc-6e1b-498c-aed1-31b49d1d2bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today()\n",
    "(end.strftime('%Y-%m-%d') == today.strftime('%Y-%m-%d')) and (today.strftime('%H') > str(17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9beb80-e105-4eef-9be7-d870cc4ffce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(today.strftime('%H') > str(17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398de7a9-0ecb-4ccc-abae-de3310784ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def new_tkr_data(new_tickers,df_to_store, df_path):\n",
    "    pass'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43093702-dffe-45ed-85e3-733b55e8f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''all_ticker_df, ticker_list, new_tickers = update_tickers(combined_tickers_csv)\n",
    "\n",
    "if new_tickers !=[]:\n",
    " \n",
    "    start = datetime.datetime(2015, 1, 1).strftime('%Y-%m-%d')\n",
    "    today_date = datetime.datetime.strptime(date.today().strftime('%Y-%m-%d'), \"%Y-%m-%d\") \n",
    "    new_stocks = yf.download(new_tickers, start=start, end=today_date)\n",
    "    idx = latest_prices.index.intersection(new_stocks.index)\n",
    "    df = new_stocks.loc[idx].join(latest_prices.loc[idx]).sort_index(level=0, axis=1)\n",
    "    df.to_csv(updated_data)\n",
    "    print('New Tickers were added:' )\n",
    "    print(new_tickers)\n",
    "else:\n",
    "    print('no new stocks added')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c24ccf-6ea9-4cbb-ac92-48d4c1763249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# latest_prices[('Adj Close', 'CTA')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065c5fd-20aa-46d5-af72-6b234c5dae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''s = 'CYA'\n",
    "s in ticker_list'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c334dd1-9acc-4cf2-b7ab-8f5f1c30a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_stock_prices[('Adj Close','CYA')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6fe14f-9668-4919-9474-2710dfc78c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aae772-e589-4462-aaa9-79aaa834ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_last_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472dee7a-1ba6-4abe-bfd5-f9ef44881089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea6985-f7ec-49c2-b22e-8162fa0e75cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78e502-520f-4ec8-8796-8c98f9bf9d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7b897-676d-4c7b-b285-1f074d8f7b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab272a-55ff-437d-868d-ad85ea9f0df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf26ec-8724-4eb2-86f9-13bada93d04d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
